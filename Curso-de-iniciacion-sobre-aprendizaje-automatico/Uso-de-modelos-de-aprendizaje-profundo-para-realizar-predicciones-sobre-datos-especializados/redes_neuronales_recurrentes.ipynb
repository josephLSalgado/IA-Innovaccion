{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "3e4985cd88b3a56a52b003f0882d181d8cd7ec7ac144250e5d6b471c317680e4"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this!\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LSTM\n",
    "from keras.callbacks import LambdaCallback, ModelCheckpoint\n",
    "import numpy as np\n",
    "import random, sys, io, string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "﻿The Time Traveller (for so it will be convenient to speak of him) was expounding a recondite matter to us. His pale grey eyes shone and twinkled, and his usually pale face was flushed and animated.\ntext length: 174201 characters\nunique characters: 39\n"
     ]
    }
   ],
   "source": [
    "text = io.open('Data/The Time Machine.txt', encoding = 'UTF-8').read()\n",
    "\n",
    "# Let's have a look at some of the text\n",
    "print(text[0:198])\n",
    "\n",
    "# This cuts out punctuation and make all the characters lower case\n",
    "text = text.lower().translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "# Character index dictionary\n",
    "charset = sorted(list(set(text)))\n",
    "index_from_char = dict((c, i) for i, c in enumerate(charset))\n",
    "char_from_index = dict((i, c) for i, c in enumerate(charset))\n",
    "\n",
    "print('text length: %s characters' %len(text))\n",
    "print('unique characters: %s' %len(charset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "number of training sequences: 43541\n"
     ]
    }
   ],
   "source": [
    "sequence_length = 40\n",
    "step = 4\n",
    "\n",
    "sequences = []\n",
    "target_chars = []\n",
    "for i in range(0, len(text) - sequence_length, step):\n",
    "    sequences.append([text[i: i + sequence_length]])\n",
    "    target_chars.append(text[i + sequence_length])\n",
    "print('number of training sequences:', len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot vectorise\n",
    "\n",
    "X = np.zeros((len(sequences), sequence_length, len(charset)), dtype=np.bool)\n",
    "y = np.zeros((len(sequences), len(charset)), dtype=np.bool)\n",
    "\n",
    "for n, sequence in enumerate(sequences):\n",
    "    for m, character in enumerate(list(sequence[0])):\n",
    "        X[n, m, index_from_char[character]] = 1\n",
    "    y[n, index_from_char[target_chars[n]]] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(128, input_shape = (X.shape[1], X.shape[2])))\n",
    "\n",
    "model.add(Dense(y.shape[1], activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this, but do not edit.\n",
    "# It helps generate the text and save the model epochs.\n",
    "\n",
    "# Generate new text\n",
    "def on_epoch_end(epoch, _):\n",
    "    diversity = 0.5\n",
    "    print('\\n### Generating text with diversity %0.2f' %(diversity))\n",
    "\n",
    "    start = random.randint(0, len(text) - sequence_length - 1)\n",
    "    seed = text[start: start + sequence_length]\n",
    "    print('### Generating with seed: \"%s\"' %seed[:40])\n",
    "\n",
    "    output = seed[:40].lower().translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    print(output, end = '')\n",
    "\n",
    "    for i in range(500):\n",
    "        x_pred = np.zeros((1, sequence_length, len(charset)))\n",
    "        for t, char in enumerate(output):\n",
    "            x_pred[0, t, index_from_char[char]] = 1.\n",
    "\n",
    "        predictions = model.predict(x_pred, verbose=0)[0]\n",
    "        exp_preds = np.exp(np.log(np.asarray(predictions).astype('float64')) / diversity)\n",
    "        next_index = np.argmax(np.random.multinomial(1, exp_preds / np.sum(exp_preds), 1))\n",
    "        next_char = char_from_index[next_index]\n",
    "\n",
    "        output = output[1:] + next_char\n",
    "\n",
    "        print(next_char, end = '')\n",
    "    print()\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "# Save the model\n",
    "checkpoint = ModelCheckpoint('Models/model-epoch-{epoch:02d}.hdf5', \n",
    "                             monitor = 'loss', verbose = 1, save_best_only = True, mode = 'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/3\n",
      "340/341 [============================>.] - ETA: 0s - loss: 2.7455\n",
      "### Generating text with diversity 0.50\n",
      "### Generating with seed: \"r the clinging hands slipped from me the\"\n",
      "r the clinging hands slipped from me the the  an te thy at so se  heli hle in ti in n s ime  mate  an tae wi t tred ter i ten tooed tee s fao w we o  he t aa iot ai e w ae an pe te cn the n e ine te  tor the ae e the t e me me in the  he s on le t ie s d d sor t s t toithe the anat ts an ti the an bhi le ai ace s ror the the the w anre tee the  arp ai the the ne mer irh aare toune the me the  hu iur tr the t te s fe tore tiin the tre bi he coe n the a d te iae s thes tle mes len wan  s selon the tse t me ina fed d e toe the ti th s pe\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.74548, saving model to Models\\model-epoch-01.hdf5\n",
      "341/341 [==============================] - 47s 137ms/step - loss: 2.7455\n",
      "Epoch 2/3\n",
      "340/341 [============================>.] - ETA: 0s - loss: 2.3587\n",
      "### Generating text with diversity 0.50\n",
      "### Generating with seed: \"elped the editor on with his coat the me\"\n",
      "elped the editor on with his coat the me at in theg ind the hand wore and ond the se the chat out or ale toi s awe fot io the gas allit the s core the the the wand the for the t inre nor the she mhe thes ind the the theut and the chat the s the th on the the thet and fone t an ind the the on the chere the thi the the cat sathe the the the in the ghe the the the s an the ind wh le pare wan tha the ind the wan on the mot le the ig sale aft the woug are ind the the the be the the the wos and the torf an the “as soule in tis th and ind ur\n",
      "\n",
      "Epoch 00002: loss improved from 2.74548 to 2.35871, saving model to Models\\model-epoch-02.hdf5\n",
      "341/341 [==============================] - 48s 141ms/step - loss: 2.3587\n",
      "Epoch 3/3\n",
      "340/341 [============================>.] - ETA: 0s - loss: 2.2239\n",
      "### Generating text with diversity 0.50\n",
      "### Generating with seed: \"r filled my ears and a strange dumb conf\"\n",
      "r filled my ears and a strange dumb conf the pacg hal irathong led ind int in the seed toe sound the ald the the the iust and rat ing of the cored lestin the the wade toe the sort the the the s ind and the seend the crapt in the the the path the the the lore the and me the s at the che ind the the shing the the the bleatle the ind it tor lach the batt and for the in in the the poresling and the ther the ang on the gore to the thith i the that the the lithire the the was ind and the then ind the ind thi mad the the thes the the the the\n",
      "\n",
      "Epoch 00003: loss improved from 2.35871 to 2.22379, saving model to Models\\model-epoch-03.hdf5\n",
      "341/341 [==============================] - 57s 168ms/step - loss: 2.2238\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25d38ddcfd0>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "model.fit(X, y, batch_size = 128, epochs = 3, callbacks = [print_callback, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loading model... model loaded\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "print(\"loading model... \", end = '')\n",
    "\n",
    "model = load_model('Models/arthur-model-epoch-30.hdf5')\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam')\n",
    "\n",
    "print(\"model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "text length: 3645951 characters\nunique characters: 43\n"
     ]
    }
   ],
   "source": [
    "text = io.open('Data/Arthur tales.txt', encoding='UTF-8').read()\n",
    "\n",
    "# Cut out punctuation and make lower case\n",
    "text = text.lower().translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "# Character index dictionary\n",
    "charset = sorted(list(set(text)))\n",
    "index_from_char = dict((c, i) for i, c in enumerate(charset))\n",
    "char_from_index = dict((i, c) for i, c in enumerate(charset))\n",
    "\n",
    "print('text length: %s characters' %len(text))\n",
    "print('unique characters: %s' %len(charset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "### Generating text with diversity 0.50\n",
      "### Generating with seed: \"m the object of his journey “i have none\"\n",
      "m the object of his journey “i have none” he replied  “and then said the earl “if thou wilt never be but a lady of the forest said sir tristram i will take the sword to the court and that will not meet and when they were brought to the earth and then he saw a fair thing field in the forest and sir gawaine to his enemies and then sir gawaine said all the death of my power i was sir lancelot and sir launcelot by the faith of his horse with the chamber and so as he was come and then sir tristram heard that he came to the castle and there was a chamber that he had never marvel that we shall not do so much as i may not be sir gawaine and for the kings son that ye shall be given for thee who shall be able to be brought out of him and that was the good knight when the king and the strongest man saw he said with the knight and this is he that is your name to her the heart of the tower of the sangreal the son of kaw and gwynn the son of gwylin the son of gwyn and gwenhwyvar the son of lludd and the horses fast and the space of elends and their spears and he said on the court and the door in the world that they came to the court and when sir gareth saw the varlet that it was in his hand and sir gawain was the three mighty man and horse and all the knights and the lady they saw the strongest scarf and the maidens and the three hundred knights and the king of northumberland and sir gawaine struck him all the horses shoulder and brought them down to the castle and said to him “i will go to him”  “i will go and then the first and he had b\n"
     ]
    }
   ],
   "source": [
    "# Generate text\n",
    "\n",
    "diversity = 0.5\n",
    "print('\\n### Generating text with diversity %0.2f' %(diversity))\n",
    "\n",
    "sequence_length = 50\n",
    "\n",
    "# Next we'll make a starting point for our text generator\n",
    "\n",
    "###\n",
    "# REPLACE <writeSentence> WITH A SENTENCE OF AT LEAST 50 CHARACTERS\n",
    "###\n",
    "# seed = \"<writeSentence>\"\n",
    "###\n",
    "\n",
    "# seed = seed.lower().translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "###\n",
    "# OR, ALTERNATIVELY, UNCOMMENT THE FOLLOWING TWO LINES AND GRAB A RANDOM STRING FROM THE TEXT FILE\n",
    "###\n",
    "\n",
    "start = random.randint(0, len(text) - sequence_length - 1)\n",
    "seed = text[start: start + sequence_length]\n",
    "\n",
    "print('### Generating with seed: \"%s\"' %seed[:40])\n",
    "\n",
    "output = seed[:sequence_length].lower().translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "print(output, end = '')\n",
    "\n",
    "for i in range(1500):\n",
    "    x_pred = np.zeros((1, sequence_length, len(charset)))\n",
    "    for t, char in enumerate(output):\n",
    "        x_pred[0, t, index_from_char[char]] = 1.\n",
    "\n",
    "    predictions = model.predict(x_pred, verbose=0)[0]\n",
    "    exp_preds = np.exp(np.log(np.asarray(predictions).astype('float64')) / diversity)\n",
    "    next_index = np.argmax(np.random.multinomial(1, exp_preds / np.sum(exp_preds), 1))\n",
    "    next_char = char_from_index[next_index]\n",
    "\n",
    "    output = output[1:] + next_char\n",
    "\n",
    "    print(next_char, end = '')\n",
    "print()"
   ]
  }
 ]
}