{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.9.0 64-bit",
   "display_name": "Python 3.9.0 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "2740b07bebd5a9538dcad413d55b5f8f7bc0dae380b851836f69cf85491ff86f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "### Importamos las bibliotecas de funciones que vamos a utilizar."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcionalidades para conectarnos con nuestro recurso de Cognitive Services\n",
    "# y validar nuestro acceso.\n",
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
    "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "\n",
    "# Paquetería de Python para acceder a recursos de la máquina.\n",
    "from array import array\n",
    "import os\n",
    "from PIL import Image # Este es para trabajar con imágenes.\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "source": [
    "### Lo primero es que necesitamos autenticar nuestro acceso para consumir el recurso."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "endpoint = \"Endpoint - extremo\"\n",
    "subscription_key = \"Clave\"\n",
    "\n",
    "computervision_client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(subscription_key))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 6,
   "outputs": []
  },
  {
   "source": [
    "### Procedemos a consumir el servicio para analizar una imagen."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ponemos un URL de la imagen que vamos a analizar\n",
    "remote_image_url = \"https://www.eloccidental.com.mx/incoming/7djvfi-talent-land_dia3.jpg/ALTERNATES/LANDSCAPE_400/Talent%20land_d%C3%ADa3.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "===== Vamos a describir el contenido de la imagen :D =====\n"
     ]
    }
   ],
   "source": [
    "# Descripción de los contenidos de la imagen\n",
    "print(\"===== Vamos a describir el contenido de la imagen :D =====\")\n",
    "# Consumimos el servicio de Computer Vision\n",
    "description_results = computervision_client.describe_image(remote_image_url )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'captions': [{'confidence': 0.46848228573799133,\n               'text': 'a group of people in a classroom'}],\n 'metadata': {'format': 'Jpeg', 'height': 250, 'width': 400},\n 'request_id': 'eae0c6ab-cb98-47e0-ae77-fce5900748d1',\n 'tags': ['person', 'child', 'group', 'crowd']}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(description_results.as_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Descripción de la imagen: \n'a group of people in a classroom' with confidence 46.85%\n"
     ]
    }
   ],
   "source": [
    "# Jala las descripciones de la respuesta\n",
    "print(\"Descripción de la imagen: \")\n",
    "if (len(description_results.captions) == 0):\n",
    "    print(\"No description detected.\")\n",
    "else:\n",
    "    for caption in description_results.captions:\n",
    "        print(\"'{}' with confidence {:.2f}%\".format(caption.text, caption.confidence * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Descripción de la imagen: \nEncontré algo:\na group of people in a classroom\n"
     ]
    }
   ],
   "source": [
    "print(\"Descripción de la imagen: \")\n",
    "if len(description_results.as_dict()['captions']) > 0:\n",
    "    print(\"Encontré algo:\")\n",
    "    for elemento in description_results.as_dict()['captions']:\n",
    "        print(elemento[\"text\"])\n",
    "else:\n",
    "    print(\"No encontré nada.\")"
   ]
  }
 ]
}